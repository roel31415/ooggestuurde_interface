{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwantisering en bemonstering\n",
    "\n",
    "De meeste signalen in het leven zijn continu: drukgolven die zich door lucht voortplanten, chemische reacties, lichaamsbeweging. Om deze continue signalen te verwerken, moeten ze echter worden omgezet naar digitale representaties via een analoog-naar-digitaal converter (ADC). Een digitaal signaal verschilt op twee  manieren van zijn continue tegenhanger:\n",
    "- Het wordt **bemonsterd** op specifieke **tijdstappen**. Geluid wordt bijvoorbeeld vaak bemonsterd op 44,1 kHz (of eens per 0,023 milliseconden).\n",
    "- Het wordt **gekwantiseerd** op specifieke **spanningsniveaus**. Bijvoorbeeld, op de Arduino Uno heeft de microcontroller een 10-bit ADC, dus een binnenkomende, continue spanningsinvoer kan worden gedigitaliseerd in stappen van $\\frac{5V}{2^{10}}=4.88 mV$.\n",
    "\n",
    "In deze les zullen we audiogegevens gebruiken als ons primaire signaal. Geluid is een prachtig medium om te leren omdat we zowel het signaal kunnen **visualiseren** als **horen**. Bedenk dat een microfoon reageert op luchtdruk golven. We zullen deze golfvormen plotten, manipuleren en vervolgens afspelen. We raden aan om je koptelefoon aan te sluiten, zodat je echt de verschillen in de verschillende audiofragmenten kunt horen.\n",
    "\n",
    "## Afhankelijkheden\n",
    "\n",
    "Voor dit notebook is [LibROSA](https://librosa.github.io/librosa/index.html) vereist - een python pakket voor muziek- en audioanalyse. Dit wordt mee geinstalleerd via dit notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gebruikte bibliotheken\n",
    "\n",
    "Hieronder staat heel wat Python code waarmee externe bibliotheken worden ingelezen. Klik gewoon 2x op 'play' zodat de notebook deze code zal uitvoeren. Je gaat er niet veel van merken, maar deze stap is nodig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt # matplot lib is the premiere plotting lib for Python: https://matplotlib.org/\n",
    "# for creating a responsive plot\n",
    "%matplotlib widget\n",
    "import numpy as np # numpy is the premiere signal handling library for Python: http://www.numpy.org/\n",
    "import scipy as sp # for signal processing\n",
    "from scipy import signal\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_to_axes(ax, s, sampling_rate, title=None, signal_label=None, marker=None):\n",
    "    '''Plots a sine wave s with the given sampling rate\n",
    "    \n",
    "    Parameters:\n",
    "    ax: matplot axis to do the plotting\n",
    "    s: numpy array\n",
    "    sampling_rate: sampling rate of s\n",
    "    title: chart title\n",
    "    signal_label: the label of the signal\n",
    "    '''\n",
    "    ax.plot(s, label=signal_label, marker=marker, alpha=0.9)\n",
    "    ax.set(xlabel=\"Samples\")\n",
    "    ax.set(ylabel=\"Amplitude\")\n",
    "    if signal_label is not None:\n",
    "        ax.legend()\n",
    "\n",
    "    # we use y=1.14 to make room for the secondary x-axis\n",
    "    # see: https://stackoverflow.com/questions/12750355/python-matplotlib-figure-title-overlaps-axes-label-when-using-twiny\n",
    "    if title is not None:\n",
    "        ax.set_title(title, y=1.1)\n",
    "    \n",
    "    ax.grid()\n",
    "\n",
    "    # add in a secondary x-axis to draw the x ticks as time (rather than samples)\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xlim(ax.get_xlim())\n",
    "    \n",
    "    ax_ticks = ax.get_xticks()[1:-1]\n",
    "    ax2_tick_labels = ax.get_xticks()[1:-1] / sampling_rate\n",
    "\n",
    "    num_samples_shown = ax.get_xlim()[1] - ax.get_xlim()[0]\n",
    "    time_shown = num_samples_shown / sampling_rate\n",
    "    if time_shown < 1:\n",
    "        ax2.set_xlabel(\"Time (ms)\")\n",
    "        # format with 'g' causes insignificant trailing zeroes to be removed\n",
    "        # https://stackoverflow.com/a/2440708 but also uses scientific notation, oh well!\n",
    "        ax2_tick_labels = [f\"{x * 1000:.1f}\" for x in ax2_tick_labels]\n",
    "    else:\n",
    "        ax2.set_xlabel(\"Time (secs)\")\n",
    "        ax2_tick_labels = ['{:.2f}'.format(x) for x in ax2_tick_labels]\n",
    "\n",
    "    ax2.set_xticks(ax_ticks)\n",
    "    ax2.set_xticklabels(ax2_tick_labels)\n",
    "\n",
    "def plot_signal(s, sampling_rate, title = None, xlim_zoom = None, highlight_zoom_area = True):\n",
    "    '''Plots time-series data with the given sampling_rate and xlim_zoom'''\n",
    "    \n",
    "    plot_title = title\n",
    "    if plot_title is None:\n",
    "        plot_title = f\"Sampling rate: {sampling_rate} Hz\"\n",
    "\n",
    "    if xlim_zoom == None:\n",
    "        fig, axes = plt.subplots(1, 1, figsize=(15,6))\n",
    "        \n",
    "        plot_signal_to_axes(axes, s, sampling_rate, plot_title)\n",
    "        return (fig, axes)\n",
    "    else:\n",
    "        #fig, axes = plt.subplots(1, 2, figsize=(15,6), sharey=True, gridspec_kw={'width_ratios': [2, 1]})\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12,6))\n",
    "        plot_signal_to_axes(axes[0], s, sampling_rate, plot_title)\n",
    "        \n",
    "        # if(xlim_zoom == None):\n",
    "        #     xlim_zoom = get_random_xzoom(len(audio_data), 0.1)\n",
    "        \n",
    "        if highlight_zoom_area:\n",
    "            # yellow highlight color: color='#FFFBCC'\n",
    "            axes[0].axvspan(xlim_zoom[0], xlim_zoom[1], color='orange', alpha=0.3)\n",
    "            \n",
    "        axes[1].set_xlim(xlim_zoom)\n",
    "        zoom_title = f\"Signal zoomed: {int(xlim_zoom[0])} - {int(xlim_zoom[1])} samples\"\n",
    "        plot_signal_to_axes(axes[1], s, sampling_rate, zoom_title)\n",
    "        axes[1].set_ylabel(None)\n",
    "        fig.tight_layout()\n",
    "        return (fig, axes)\n",
    "\n",
    "def create_sine_wave(freq, sampling_rate, total_time_in_secs = None, return_time = False):\n",
    "    '''Creates a sine wave with the given frequency, sampling rate, and length'''\n",
    "    \n",
    "    # if the total time in secs is None, then return one period of the wave\n",
    "    if total_time_in_secs is None:\n",
    "        total_time_in_secs = 1 / freq\n",
    "\n",
    "    # Create an array from 0 to total_time_in_secs * sampling_rate (and then divide by sampling\n",
    "    # rate to get each time_step)\n",
    "    time = np.arange(total_time_in_secs * sampling_rate) / sampling_rate\n",
    "    \n",
    "    # Could also generate this signal by:\n",
    "    # time = np.linspace(0, total_time_in_secs, int(total_time_in_secs * sampling_rate), endpoint=False)\n",
    "\n",
    "    sine_wave = np.sin(2 * np.pi * freq * time)\n",
    "\n",
    "    # or, once the sample is made:\n",
    "    # time = np.linspace(0, len(s) / sampling_rate, num=len(s))\n",
    "\n",
    "    if return_time is False:\n",
    "        return sine_wave\n",
    "    else:\n",
    "        return (time, sine_wave)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deel 1 - Kwantisatie\n",
    "\n",
    "Kwantisatie verwijst naar het proces van het transformeren van een analoog signaal, dat een continue reeks waarden heeft, naar een digitaal signaal, dat een discrete set heeft. Zie de figuur hieronder uit het artikel over [Kwantisatie](https://en.wikipedia.org/wiki/Quantization_(signal_processing)) op Wikipedia.\n",
    "\n",
    "| 2-bits Kwantisatie | 3-bits Kwantisatie |\n",
    "| :-----: | :-----: |\n",
    "| ![2-bit resolution](https://upload.wikimedia.org/wikipedia/commons/b/b1/2-bit_resolution_analog_comparison.png) | ![3-bit resolution](https://upload.wikimedia.org/wikipedia/commons/b/b7/3-bit_resolution_analog_comparison.png) |\n",
    "| 2-bits resolutie kwantiseert het analoge signaal in vier niveaus ($2^{2}$) | 3-bits resolutie kwantiseert in acht niveaus ($2^{3}$) |\n",
    "\n",
    "De ATmega328 op de Arduino Uno heeft bijvoorbeeld een 10-bits analoog-naar-digitaal (ADC) converter terwijl de ESP32 een 12-bits ADC heeft. Omdat de ATmega328 op 5V werkt, is de stapgrootte van de ADC $\\frac{5V}{2^{10}} = 4.88mV$. Dit is de kleinste waarneembare verandering die je kunt observeren op de analoge invoerpinnen van de Uno. In contrast, de ESP32 werkt op 3.3V en heeft een hogere bitresolutie (12 bits), dus de ADC heeft veel fijnere discretisaties: $\\frac{3.3V}{2^{12}} = 0.806mV$—ongeveer, zes keer meer precisie dan de Uno!\n",
    "\n",
    "## Karakterisering van kwantisatiefout\n",
    "\n",
    "Een gedigitaliseerde sample kan een maximale fout hebben van de helft van de discretisatiestap (*d.w.z.,* ±½ van de Least Significant Bit (LSB)). Waarom? Omdat wanneer we een analoog waarde omzetten naar een digitale, we naar het dichtstbijzijnde gehele getal afronden. Stel je een spanningsignaal van 0.2271V voor op een Uno's analoge invoerpin, dit ligt bijna halverwege tussen de stappen 0.2246V en 0.2295V, wat zou resulteren in een fout van $\\frac{4.89mV}{2}$ (en wordt omgezet naar 47 of 48 via `analogRead` van Arduino)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoe beïnvloedt kwantisatie audio signalen?\n",
    "Voor de onderstaande voorbeelden werken we met vooraf gedigitaliseerde audiogolven bemonsterd op 44.1kHz en gekwantiseerd op 16-bits. Dus, hoewel het geen echt continue sample is (natuurlijk niet, het is al een digitaal signaal!), zullen we het losjes als zodanig behandelen. En we zullen \"downsamplen\" om de effecten van kwantisatieniveaus en bemonsteringssnelheden te onderzoeken.\n",
    "\n",
    "Laten we een initiële 16-bit, 44.1kHz geluidsgolfvorm van iemand die het woord \"Hallo\" zegt, laden, visualiseren en afspelen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate, audio_data_16bit = sp.io.wavfile.read('HumanVoice-Hello_16bit_44.1kHz_mono.wav')\n",
    "\n",
    "print(f\"Sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"Number of channels = {len(audio_data_16bit.shape)}\")\n",
    "print(f\"Total samples: {audio_data_16bit.shape[0]}\")\n",
    "\n",
    "if len(audio_data_16bit.shape) == 2:\n",
    "    # convert to mono\n",
    "    audio_data_16bit = convert_to_mono(audio_data_16bit)\n",
    "    \n",
    "length_in_secs = audio_data_16bit.shape[0] / sampling_rate\n",
    "print(f\"length = {length_in_secs}s\")\n",
    "print(audio_data_16bit)\n",
    "quantization_bits = 16\n",
    "print(f\"{quantization_bits}-bit audio ranges from -{2**(quantization_bits - 1)} to {2**(quantization_bits - 1) - 1}\")\n",
    "print(f\"Max value: {np.max(audio_data_16bit)} Avg value: {np.mean(audio_data_16bit):.2f}\")\n",
    "\n",
    "# We'll highlight and zoom in on the orange part of the graph controlled by xlim_zoom\n",
    "xlim_zoom = (11000, 12500) # you may want to change this depending on what audio file you have loaded\n",
    "plot_signal(audio_data_16bit, sampling_rate, quantization_bits, xlim_zoom = xlim_zoom)\n",
    "ipd.Audio(audio_data_16bit, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-bit kwantisatie\n",
    "\n",
    "We kunnen de 16-bits audio omzetten naar andere kwantisatieniveaus om te zien en te horen hoe kwantisatie de kwaliteit beïnvloedt.\n",
    "\n",
    "We beginnen met een 8-bit kwantisatie; pas de parameter aan in de volgende code blok, voer de daaropvolgende codeblok uit en bekijk het resultaat. Vergelijk ook telkens met de oorspronkelijke 16-bit versie hierboven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the quantization level here\n",
    "quantization_bits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float\n",
    "audio_data_float = audio_data_16bit / 2**16 # 16 bit audio\n",
    "\n",
    "# Let's try with n-bit audio\n",
    "audio_data_nbit = audio_data_float * 2**quantization_bits\n",
    "audio_data_nbit = audio_data_nbit.astype(int)\n",
    "print(audio_data_nbit)\n",
    "print(f\"{quantization_bits}-bit audio ranges from -{2**(quantization_bits - 1)} to {2**(quantization_bits - 1) - 1}\")\n",
    "print(f\"Max value: {np.max(audio_data_nbit)} Avg value: {np.mean(audio_data_nbit):.2f}\")\n",
    "\n",
    "plot_signal(audio_data_nbit, sampling_rate, quantization_bits, xlim_zoom = xlim_zoom)\n",
    "ipd.Audio(audio_data_nbit, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vragen** (vul hieronder je antwoord in)\n",
    "\n",
    "- Welk bereik (minimum en maximum van de amplitude) heeft het geluidsignaal na kwantisatie op 8 bits?\n",
    "\n",
    "- Waar komen deze waarden vandaan?\n",
    "\n",
    "- Kijk goed naar de golfvorm, kun je verschillen opmerken met 16-bits audio? \n",
    "\n",
    "- En hoe zit het wanneer je luistert naar de 8-bits versus de 16-bits versie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-bit kwantisatie\n",
    "Hoe zit het met 6-bits? Pas de parameter quantization_bits aan tot 6 om dit uit te proberen.\n",
    "\n",
    "**Vragen**\n",
    "- Hoor je degradaties in het signaal? Omschrijf wat je hoort.\n",
    "  \n",
    "- En kan je al gekwantiseerde stappen zien in de ingezoomde golfvorm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit kwantisatie\n",
    "Pas nu de parameter quantization_bits aan tot 4.\n",
    "\n",
    "**Vragen**\n",
    "- Hoor je degradaties in het signaal? Omschrijf wat je hoort.\n",
    "  \n",
    "- En wat zie je in de ingezoomde golfvorm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenteer met een ander geluidsfragment\n",
    "\n",
    "We laden nu een ander geluidsfragment in en onderzoeken de invloed van de kwantisatie. We letten nu vooral op het verschil in kwaliteit tussen luide en stille delen van het geluidssignaal.\n",
    "\n",
    "Zoom in op een deel van het signaal waarin zowel luide als zachte stukken zitten. Inzoomen kan je met het vierkantje linksonder in het menu van de grafiek. Doe dit voor verschillende waarden van quantization_bits. Begin met 8 en ga zo naar 6, 4 en 3 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verander deze parameter om het aantal bits te wijzigen\n",
    "quantization_bits = 8 # change this and see what happens!\n",
    "# --------------------------------------\n",
    "\n",
    "# Change this wave file to any 16-bit audio sample\n",
    "your_sound_file = 'Guitar_MoreThanWords_16bit_44.1kHz_stereo.wav'\n",
    "your_sampling_rate, your_audio_data_16_bit = sp.io.wavfile.read(your_sound_file)\n",
    "\n",
    "print(f\"Sampling rate: {your_sampling_rate} Hz\")\n",
    "print(f\"Number of channels = {len(your_audio_data_16_bit.shape)}\")\n",
    "print(f\"Total samples: {your_audio_data_16_bit.shape[0]}\")\n",
    "\n",
    "if len(your_audio_data_16_bit.shape) == 2:\n",
    "    # convert to mono\n",
    "    print(\"Converting stereo audio file to mono\")\n",
    "    your_audio_data_16_bit = your_audio_data_16_bit.sum(axis=1) / 2\n",
    "\n",
    "# Convert to float\n",
    "your_audio_data_float = your_audio_data_16_bit / 2**16 # 16 bit audio\n",
    "\n",
    "your_audio_data_quantized = your_audio_data_float * 2**quantization_bits\n",
    "your_audio_data_quantized = your_audio_data_quantized.astype(int)\n",
    "print(your_audio_data_quantized)\n",
    "print(f\"{quantization_bits}-bit audio ranges from -{2**(quantization_bits - 1)} to {2**(quantization_bits - 1) - 1}\")\n",
    "print(f\"Max value: {np.max(your_audio_data_quantized)} Avg value: {np.mean(your_audio_data_quantized):.2f}\")\n",
    "\n",
    "xlim_zoom = (45000, 50000) # make sure to change the zoom range too\n",
    "plot_signal(your_audio_data_16_bit, sampling_rate, 16, xlim_zoom = xlim_zoom)\n",
    "plot_signal(your_audio_data_quantized, sampling_rate, quantization_bits, xlim_zoom = xlim_zoom)\n",
    "ipd.Audio(your_audio_data_quantized, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vragen**\n",
    "\n",
    "- Als je inzoomt op een gebied met luide en zachte stukken, welk verschil zie je dan tussen beide?\n",
    "\n",
    "- Bij een kwantisatie naar 6 bits, hoeveel verschillende waardes zie je voor het zachte deel van het signaal (met een amplitude van 1)? \n",
    "  \n",
    "- En voor het luide deel van het signaal (amplitude 10)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusie\n",
    "\n",
    "Een kleiner signaal (zachte deel van de muziek) gebruikt minder digitale waardes dan een groter signaal (het luide deel). \n",
    "Een klein analoog signaal omzetten naar een digitaal signaal levert dus een kwalitatief minder goed digitaal signaal op dan een groot analoog signaal. \n",
    "\n",
    "Een Analoog Digitaal Convertor van 5V en N bits zet een analoog signaal van 5V om in $2^{N}$ niveaus, zoals we in de grafieken hebben gezien.  \n",
    "We hebben minstens 1 niveau per millivolt nodig om het signaal te kunnen detecteren.\n",
    "    \n",
    "**vragen**\n",
    "\n",
    "- Ons oog produceert een signaal van ongeveer 1 mV. Hoeveel bits denk je nodig te hebben om dit signaal te digitaliseren?  \n",
    "\n",
    "- Onze ADC is beperkt tot 10 bits. Wat moet je doen? \n",
    "\n",
    "- Wat is je conclusie uit dit experiment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deel 2 - Bemonstering\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/50/Signal_Sampling.png\" width=\"500\">\n",
    "<center>Een continu signaal (groen) wordt elke $\\frac{1}{T}$ Hz bemonsterd (blauw). Bron: <a href=\"https://en.wikipedia.org/wiki/Sampling_(signal_processing)\">Wikipedia</a></center>\n",
    "\n",
    "\n",
    "\n",
    "Naast kwantisatie is de andere belangrijke factor bij het digitaliseren van een signaal de snelheid waarmee het analoge signaal wordt bemonsterd (of vastgelegd). Hoe vaak moet je een signaal monsteren om het perfect te reconstrueren?\n",
    "\n",
    "## Nyquist bemonsteringstheorema\n",
    "Het antwoord kan je verrassen en omvat een van de meest fundamentele (en interessante) stellingen in signaalverwerking: het Nyquist-bemonsteringstheorema, die stelt dat een continu signaal gereconstrueerd kan worden zolang er twee monsters per periode zijn voor de hoogste frequentiecomponent in het onderliggende signaal.\n",
    "\n",
    "Dat wil zeggen, voor een perfecte reconstructie moet onze digitale bemonsteringsfrequentie $f_s$ minstens twee keer zo snel zijn als de snelste frequentie in ons continue signaal: $f_s = 2 * max(analog_{freq})$.\n",
    "\n",
    "Bijvoorbeeld, stel dat we een analoog signaal hebben bestaande uit frequenties tussen 0 en 2.000 Hz. Om dit signaal goed te digitaliseren, moeten we monsteren bij $2 * 2.000Hz$. Dus, $f_s$ moet 4.000Hz zijn.\n",
    "\n",
    "Stel je nu voor dat het snelste waarmee onze digitizer kan bemonsteren 6.000 Hz is: welk frequentiebereik kunnen we dan goed vastleggen? Omdat we minimaal twee monsters per periode nodig hebben voor een juiste reconstructie, kunnen we alleen signalen vastleggen die veranderen met een frequentie van 0 tot maximaal 3.000Hz. Deze limiet van 3.000Hz wordt de Nyquist-frequentie of Nyquist-limiet genoemd: het is $\\frac{1}{2}$ van de bemonsteringsfrequentie $f_s$.\n",
    "\n",
    "Voor veel toepassingen met betrekking tot Mens-Computerinteractie is bemonstering bij 4kHz meer dan voldoende. Dit maakt analyse van elk signaal tussen 0-2kHz mogelijk. Menselijke beweging - wandelbeweging, ledemaatbeweging, vingerbewegingen, enzovoort - verandert gewoon niet zo snel. Zelfs elektro-encefalogrammen (EEG), die elektrische activiteit in de hersenen meten, worden vaak bemonsterd bij 500-1000Hz. Echter, voor het opnemen van geluid (mensen kunnen horen tussen ~0-20kHz), zijn snellere bemonsteringsfrequenties nodig.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aliasing\n",
    "\n",
    "Wat gebeurt er als we een signaal monsteren met frequentiecomponenten groter dan de Nyquist-limiet? We krijgen [aliasing](https://en.wikipedia.org/wiki/Aliasing#Sampling_sinusoidal_functions) - een probleem waarbij de hogere frequentiecomponenten van een signaal (die groter zijn dan de Nyquist-limiet) verschijnen als lagere frequentiecomponenten. Zoals Smith opmerkt, \"net zoals een crimineel een aangenomen naam of identiteit kan aannemen (een alias), neemt de sinusgolf een andere frequentie aan die niet van hemzelf is.\" En misschien nog kwalijker, er is niets in de bemonsterde gegevens dat suggereert dat er aliasing heeft plaatsgevonden: \"de sinusoïde heeft zijn ware identiteit volledig verborgen.\" Zie figuur hieronder.\n",
    "\n",
    "<img src=\"NyquistSamplingTheoremAndAliasing_1500w.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliasing voorbeeld\n",
    "\n",
    "Laten we eens naar een voorbeeld kijken. Hier zullen we vier signalen bemonsteren met een bemonsteringsfrequentie van 50Hz: `signaal1 = 5Hz`, `signaal2 = 10Hz`, `signaal3 = 20Hz`, en `signaal4 = 60Hz`. Alleen `signaal4` bevindt zich boven onze Nyquist-limiet, die $\\frac{1}{2} * 50Hz = 25Hz$ is. Wat zal er gebeuren?\n",
    "\n",
    "De \"monsters\" worden weergegeven als verticale lijnen met vierkante rechthoekige markeringen. Wat observeer je? Let goed op `signaal4`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time_in_secs = 0.2\n",
    "\n",
    "# Create our \"real-world\" continuous signals (which is obviously not possible on a digital computer, so we fake it)\n",
    "real_world_continuous_speed = 10000\n",
    "real_world_signal1_freq = 5\n",
    "time, real_world_signal1 = create_sine_wave(real_world_signal1_freq, real_world_continuous_speed, \n",
    "                                               total_time_in_secs, return_time = True)\n",
    "\n",
    "real_world_signal2_freq = 10\n",
    "real_world_signal2 = create_sine_wave(real_world_signal2_freq, real_world_continuous_speed, \n",
    "                                               total_time_in_secs)\n",
    "\n",
    "real_world_signal3_freq = 20\n",
    "real_world_signal3 = create_sine_wave(real_world_signal3_freq, real_world_continuous_speed, \n",
    "                                               total_time_in_secs)\n",
    "\n",
    "real_world_signal4_freq = 60\n",
    "real_world_signal4 = create_sine_wave(real_world_signal4_freq, real_world_continuous_speed, \n",
    "                                               total_time_in_secs)\n",
    "\n",
    "# Create the sampled versions of these continuous signals\n",
    "resample_factor = 200 # should be an integer\n",
    "sampled_time = time[::resample_factor]\n",
    "sampled_signal1 = real_world_signal1[::resample_factor]\n",
    "sampled_signal2 = real_world_signal2[::resample_factor]\n",
    "sampled_signal3 = real_world_signal3[::resample_factor]\n",
    "sampled_signal4 = real_world_signal4[::resample_factor]\n",
    "sampling_rate = real_world_continuous_speed / resample_factor\n",
    "print(f\"Sampling rate: {sampling_rate} Hz\")\n",
    "\n",
    "# Visualize the sampled versions\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10,13))\n",
    "axes[0].plot(time, real_world_signal1)\n",
    "axes[0].axhline(0, color=\"gray\", linestyle=\"-\", linewidth=0.5)\n",
    "axes[0].plot(sampled_time, sampled_signal1, linestyle='None', alpha=0.8, marker='s', color='black')\n",
    "axes[0].vlines(sampled_time, ymin=0, ymax=sampled_signal1, linestyle='-.', alpha=0.8, color='black')\n",
    "axes[0].set_ylabel(\"Amplitude\")\n",
    "axes[0].set_xlabel(\"Time (secs)\")\n",
    "axes[0].set_title(f\"{real_world_signal1_freq}Hz signal sampled at {sampling_rate}Hz\")\n",
    "\n",
    "axes[1].plot(time, real_world_signal2)\n",
    "axes[1].axhline(0, color=\"gray\", linestyle=\"-\", linewidth=0.5)\n",
    "axes[1].plot(sampled_time, sampled_signal2, linestyle='None', alpha=0.8, marker='s', color='black')\n",
    "axes[1].vlines(sampled_time, ymin=0, ymax=sampled_signal2, linestyle='-.', alpha=0.8, color='black')\n",
    "axes[1].set_ylabel(\"Amplitude\")\n",
    "axes[1].set_xlabel(\"Time (secs)\")\n",
    "axes[1].set_title(f\"{real_world_signal2_freq}Hz signal sampled at {sampling_rate}Hz\")\n",
    "\n",
    "axes[2].plot(time, real_world_signal3)\n",
    "axes[2].axhline(0, color=\"gray\", linestyle=\"-\", linewidth=0.5)\n",
    "axes[2].plot(sampled_time, sampled_signal3, linestyle='None', alpha=0.8, marker='s', color='black')\n",
    "axes[2].vlines(sampled_time, ymin=0, ymax=sampled_signal3, linestyle='-.', alpha=0.8, color='black')\n",
    "axes[2].set_ylabel(\"Amplitude\")\n",
    "axes[2].set_xlabel(\"Time (secs)\")\n",
    "axes[2].set_title(f\"{real_world_signal3_freq}Hz signal sampled at {sampling_rate}Hz\")\n",
    "\n",
    "axes[3].plot(time, real_world_signal4)\n",
    "axes[3].axhline(0, color=\"gray\", linestyle=\"-\", linewidth=0.5)\n",
    "axes[3].plot(sampled_time, sampled_signal4, linestyle='None', alpha=0.8, marker='s', color='black')\n",
    "axes[3].vlines(sampled_time, ymin=0, ymax=sampled_signal4, linestyle='-.', alpha=0.8, color='black')\n",
    "axes[3].set_ylabel(\"Amplitude\")\n",
    "axes[3].set_xlabel(\"Time (secs)\")\n",
    "axes[3].set_title(f\"{real_world_signal4_freq}Hz signal sampled at {sampling_rate}Hz\")\n",
    "\n",
    "fig.tight_layout(pad = 3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we eens wat beter kijken naar signaal2 = 10Hz en signaal4 = 60Hz.\n",
    "\n",
    "Kun je het zien? Het 60Hz signaal wordt bemonsterd als een 10Hz signaal. En zodra het signaal is gedigitaliseerd (zoals hier), zou er geen manier zijn om het verschil te zien tussen een werkelijk 10Hz signaal en een gealieaseerd signaal!\n",
    "\n",
    "Waarom?\n",
    "\n",
    "Kijk naar de grafieken, bij het eerste monster beginnen beide sinusoiden net; echter, bij het volgende monster heeft de 60Hz sinusoid bijna één volledige periode voltooid!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hoe beïnvloeden bemonsteringsfrequenties de geluidskwaliteit?\n",
    "\n",
    "Hieronder bemonsteren we een menselijke stem van 44,1 kHz naar: 22,5 kHz, 11.025 Hz ... 441 Hz. Voor elke bemonstering visualiseren we de originele golfvorm van 44,1 kHz en zijn bijbehorende bemonsterde tegenhanger.\n",
    "\n",
    "Wat valt je op?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to change this to some other 44.1kHz sound file\n",
    "sound_file = 'HumanVoice-Hello_16bit_44.1kHz_mono.wav' \n",
    "sampling_rate, audio_data_44100 = sp.io.wavfile.read(sound_file)\n",
    "\n",
    "print(f\"Sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"Number of channels = {len(audio_data_44100.shape)}\")\n",
    "print(f\"Total samples: {audio_data_44100.shape[0]}\")\n",
    "\n",
    "if len(audio_data_44100.shape) == 2:\n",
    "    # convert to mono\n",
    "    print(\"Converting stereo audio file to mono\")\n",
    "    audio_data_44100 = audio_data_44100.sum(axis=1) / 2\n",
    "    \n",
    "quantization_bits = 16\n",
    "xlim_zoom = (11500, 12500)\n",
    "\n",
    "plot_signal(audio_data_44100, sampling_rate, quantization_bits, xlim_zoom = xlim_zoom)\n",
    "ipd.Audio(audio_data_44100, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_factor = 10\n",
    "new_sampling_rate = sampling_rate / resample_factor\n",
    "audio_data_resampled = audio_data_44100[::resample_factor]\n",
    "resample_xlim_zoom = (xlim_zoom[0] / resample_factor, xlim_zoom[1] / resample_factor)\n",
    "\n",
    "print(f\"Sampling rate: {new_sampling_rate} Hz\")\n",
    "print(f\"Number of channels = {len(audio_data_resampled.shape)}\")\n",
    "print(f\"Total samples: {audio_data_resampled.shape[0]}\")\n",
    "\n",
    "plot_signal(audio_data_44100, sampling_rate, quantization_bits, xlim_zoom = xlim_zoom)\n",
    "ipd.Audio(audio_data_resampled, rate=new_sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bronnen\n",
    "- [Chapter 3: ADC and DAC](http://www.dspguide.com/ch3.htm), The Scientist and Engineer's Guide to Digital Signal Processing, Steven W. Smith, Ph.D.\n",
    "- [Chapter 2: Signals in the Computer](http://faculty.washington.edu/stiber/pubs/Signal-Computing/Signal%20Computing.pdf), Signal Computing: Digital Signals in the Software Domain, Stiber, Stiber, and Larson, 2020\n",
    "- [Notes on Music Information Retrieval](https://musicinformationretrieval.com/index.html)\n",
    "- [D/A and A/D](https://youtu.be/cIQ9IXSUzuM), Monty Montgomery, YouTube\n",
    "\n",
    "## Over dit Notebook\n",
    "\n",
    "This Notebook was designed and written by Professor Jon E. Froehlich at the University of Washington along with feedback from students. It is made available freely online as an [open educational resource](https://en.wikipedia.org/wiki/Open_educational_resources) at the teaching website: https://makeabilitylab.github.io/physcomp/. \n",
    "\n",
    "The [website](https://github.com/makeabilitylab/physcomp), [Notebook code](https://github.com/makeabilitylab/signals), and [Arduino code](https://github.com/makeabilitylab/arduino) are all open source using the MIT license.\n",
    "\n",
    "Het Notebook is aangepast en vertaald naar het Nederlands door Roel Truyen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "347.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
